{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from irt import IRTModel\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from beta_irt.visualization.plots import newline\n",
    "from beta_irt.visualization.plots import plot_parameters\n",
    "from irt import beta_irt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "path_data = './data/'\n",
    "path_uci = './data/UCI - 45/'\n",
    "\n",
    "# Name of data set\n",
    "name = 'polynomial'\n",
    "\n",
    "# Read csv\n",
    "data = pd.read_csv(path_uci + name + '.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "# Parameters\n",
    "rd = 42\n",
    "noise_std = np.linspace(0, 0.4, 20)\n",
    "max_std = noise_std.max()\n",
    "\n",
    "# Variable selection\n",
    "X = data.iloc[:, 0].values.reshape(-1,1)\n",
    "y = data.iloc[:, 1]\n",
    "\n",
    "# Split data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = rd)\n",
    "indexes = list(y_train.index)\n",
    "\n",
    "# Standard scale\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "# # Principal component analysis\n",
    "# pca = PCA(n_components= 1)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "# Regression Models\n",
    "models = [LinearRegression(), BayesianRidge(), svm.SVR(kernel= 'linear'), svm.SVR(kernel = 'rbf', gamma= 'scale', C = 5),\\\n",
    "     KNeighborsRegressor(), DecisionTreeRegressor(), RandomForestRegressor(),\\\n",
    "          AdaBoostRegressor(), MLPRegressor(max_iter=1000, solver= 'lbfgs'), MLPRegressor(hidden_layer_sizes= (50,50), solver = 'lbfgs', max_iter=500, activation='logistic')]\n",
    "\n",
    "# Generate abilities/parameters for BIRT and other info.\n",
    "Irt = IRTModel(models= models)\n",
    "Irt.fit(X_train = X_train, y_train = y_train)\n",
    "\n",
    "# Plot limits\n",
    "xlim = [min(X_test) - 2*max_std, max(X_test) + 2*max_std]\n",
    "ylim = [min(y_test), max(y_test)]\n",
    "\n",
    "# Edward - set seed\n",
    "ed.set_seed(rd)\n",
    "\n",
    "# Folders\n",
    "path = './beta_irt/results/'\n",
    "folder = name + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = np.zeros((len(X_test), len(noise_std)))\n",
    "responses = np.zeros((len(noise_std), len(X_test), len(models) + 3))\n",
    "abilities = np.zeros((len(noise_std), len(models) + 3))\n",
    "parameters = np.zeros((len(noise_std), len(X_test), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, noise in enumerate(noise_std):\n",
    "    # Generate noise to feature in test set\n",
    "    noise_test = np.random.normal(loc=0.0, scale= noise, size= len(X_test))\n",
    "    noises[:, i] = noise_test\n",
    "    X_test_ = X_test + noise_test.reshape(-1,1)\n",
    "    \n",
    "    # Generate IRT matrix\n",
    "    Irt.irtMatrix(X_test= X_test_, y_test= y_test, noise_std = i, normalize= True, base_models= True, name= name, rd= rd)\n",
    "    responses[i] = Irt.irt_matrix\n",
    "#     print('Noise ' + str(i))\n",
    "#     print(responses[i].reshape(1,-1).mean())\n",
    "#     print(name_)\n",
    "#     print('----------------------------------------------------------------__')\n",
    "    name_ = name + '_s' + str(len(y_test)) + '_f' + str(i) + '_sd' + str(rd)\n",
    "    \n",
    "    # Generate Items' parameters and Respondents' abilities\n",
    "    os.chdir('./beta_irt/')\n",
    "    %run -i betairt_test.py {'irt_data_'+ name_ +'.csv'}\n",
    "    os.chdir('..')\n",
    "    \n",
    "    error = pd.read_csv('./beta_irt/errors_' + name_ + '.csv')\n",
    "    abilities = pd.read_csv(path + folder + 'irt_ability_vi_'+ name_ +'_am1@0_as1@0.csv')\n",
    "    ind = list(y_test.index)\n",
    "    parameters = pd.read_csv(path + folder + 'irt_parameters_vi_'+ name_ +'_am1@0_as1@0.csv').iloc[:,:].values\n",
    "    \n",
    "    # Move files to folder    \n",
    "    if !os.path.isdir('./Results_IRT/'+ folder):\n",
    "        !mkdir {'./Results_IRT/'+ folder}\n",
    "    if !os.path.isdir('./Results_IRT/'+ folder + 'noise_' + str(i)):\n",
    "        !mkdir \n",
    "    output = './Results_IRT/'+ folder +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(X_train, y_train, label='Train set', s=24, edgecolor='k')\n",
    "plt.scatter(X_test_, y_test, label='Test set', c='red', s=24, edgecolor='k')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.xlim(xlim)\n",
    "plt.title('Train/Test Split')\n",
    "plt.legend()\n",
    "# plt.savefig('./Results_IRT/' + name + '/dataset.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is required to run 'betairt_test.py' with the same data generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-Response Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty = parameters.iloc[:,0].values\n",
    "discrimination = parameters.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = np.linspace(0.0001, 0.9999, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = np.concatenate((X_test, y_test.values.reshape(-1,1)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(concat[:,0],concat[:,1])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.ylim(ylim)\n",
    "ind = [-4, -3, -2, -1, 22, 35]\n",
    "for i, txt in enumerate(ind):\n",
    "    plt.text(concat[txt][0],concat[txt][1], ' Outlier ' + str(i+1), fontsize=8)\n",
    "if noise_std == 0:\n",
    "    plt.savefig('./Results_IRT/' + name.split('_')[0] + '/original.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameters.sort_values(by= 'difficulty', ascending= False).head())\n",
    "print(parameters.sort_values(by= 'discrimination', ascending= True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, l in enumerate([slice(0, 5, 1), slice(5, 10, 1)]):\n",
    "    if noise_std > 0:\n",
    "        f = plot_parameters(concat, delta = difficulty, a = discrimination, noise = noise, models= Irt.models[l], ylim= ylim)\n",
    "    else:\n",
    "        f = plot_parameters(concat, delta = difficulty, a = discrimination, models= Irt.models[l], ylim = ylim)\n",
    "    f.savefig('./Results_IRT/' + name.split('_')[0] + '/params_'+str(i+1)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_i = [-4, -3, -2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for sub, i in enumerate(chosen_i):\n",
    "    plt.subplot(2, 2, sub+1)\n",
    "    par = parameters.iloc[i,:].values\n",
    "    diff = par[0]\n",
    "    disc = par[1]\n",
    "    E = [beta_irt(x, diff, disc) for x in ab]\n",
    "    middle = np.where(np.array(E)>0.499)[0][:2]\n",
    "    p1 = [ab[middle[0]], E[middle[0]]]\n",
    "    p2 = [ab[middle[1]], E[middle[1]]]\n",
    "    newline(p1,p2)\n",
    "    slope = (E[middle[1]] - E[middle[0]])/(ab[middle[1]] - ab[middle[0]])\n",
    "    plt.text(p2[0], p2[1], 'slope = '+str(round(slope, 3)),fontsize=8)\n",
    "    plt.plot(ab, E,)\n",
    "    plt.plot([ab[middle[0]], ab[middle[0]]],[0, E[middle[0]]], '--r')\n",
    "    plt.plot([0, ab[middle[0]]],[E[middle[0]], E[middle[0]]], '--r')\n",
    "    plt.scatter(abilities['ability'].values[:-1], irt.iloc[i].values, marker= 'x', c = 'red')\n",
    "    plt.ylabel('Response')\n",
    "    plt.xlabel('Ability')\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.title('Outlier ' + str(sub+1))\n",
    "plt.savefig('./Results_IRT/' + name.split('_')[0] + '/instances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "for sub, i in enumerate(chosen_i):\n",
    "#     plt.subplot(2, 2, sub+1)\n",
    "    par = parameters.iloc[i,:].values\n",
    "    diff = par[0]\n",
    "    disc = par[1]\n",
    "    E = np.array([beta_irt(x, diff, disc) for x in ab])\n",
    "    Error = (1 - E)/E\n",
    "    plt.plot(ab, Error, label = 'Outlier ' + str(sub + 1))\n",
    "#     plt.plot([ab[middle[0]], ab[middle[0]]],[0, E[middle[0]]], '--r')\n",
    "#     plt.plot([0, ab[middle[0]]],[E[middle[0]], E[middle[0]]], '--r')\n",
    "    err = irt.iloc[i].values\n",
    "#     plt.scatter(abilities['ability'].values[:-1], (1-err)/err, marker= 'x', c = 'red')\n",
    "    plt.ylabel('Exp. Error')\n",
    "    plt.xlabel('Ability')\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 10.01])\n",
    "#     plt.title('')\n",
    "plt.legend()\n",
    "plt.savefig('./Results_IRT/' + name.split('_')[0] + '/error_ability.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving IRT files to 'Results_IRT' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv {'./beta_irt/irt_data_' + name + '.csv'} {'./Results_IRT/' + name.split('_')[0] + '/'}\n",
    "!mv {'./beta_irt/xtest_' + name + '.csv'} {'./Results_IRT/' + name.split('_')[0] + '/'}\n",
    "!mv {'./beta_irt/errors_' + name + '.txt'} {'./Results_IRT/' + name.split('_')[0] + '/'}\n",
    "!mv {path + folder + 'irt_ability_vi_'+ name +'_am1@0_as1@0.csv'} {'./Results_IRT/' + name.split('_')[0] + '/'}\n",
    "!mv {path + folder + 'irt_parameters_vi_'+ name +'_am1@0_as1@0.csv'} {'./Results_IRT/' + name.split('_')[0] + '/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

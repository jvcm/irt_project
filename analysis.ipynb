{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from irt import IRTModel\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "# from beta_irt.visualization.plots import newline\n",
    "# from beta_irt.visualization.plots import plot_parameters\n",
    "from irt import beta_irt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import glob\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from beta_irt.visualization.plots import plot_parameters\n",
    "# from scipy.interpolate import spline\n",
    "# from scipy.interpolate import make_interp_spline, BSpline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examplos of IRT Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilities = np.linspace(start= 0.0001, stop= 1.)\n",
    "params_1 = np.array([[0.2, 1., 2.4],\n",
    "                     [0.5, 1., 2.4],\n",
    "                     [0.7, 1., 2.4]])\n",
    "params_2 = np.array([[0.5, .5, 2.4],\n",
    "                     [0.5, 1., 2.4],\n",
    "                     [0.5, 2., 2.4]])\n",
    "colors = ['red', 'black', 'blue']\n",
    "p_str = ['dif', 'aj']\n",
    "save_name = ['IRT_Reg_Diff', 'IRT_Reg_Discr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_err(theta_i, delta_j, a_j, c_j):\n",
    "    a = ((delta_j)/(1 - delta_j))**a_j\n",
    "    b = ((theta_i)/(1 - theta_i))**-a_j\n",
    "    return a*b*c_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsz = 15\n",
    "new_style = {'grid': False}\n",
    "plt.rc('axes', **new_style)\n",
    "line_sty = 'grey'\n",
    "for n, params in enumerate([params_1, params_2]):\n",
    "    plt.figure()\n",
    "    for i, param in enumerate(params):\n",
    "        responses = []\n",
    "        for ability in abilities:\n",
    "            responses.append(exp_err(ability, param[0], param[1], param[2]))\n",
    "        plt.plot(abilities, responses, c = colors[i], label = '{} = {}'.format(p_str[n], str(param[n])))\n",
    "        if n == 0:\n",
    "            plt.plot([0, 0.7], [2.4, 2.4], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "            plt.plot([0.2, 0.2], [-.3, 2.4], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "            plt.plot([0.5, 0.5], [-.3, 2.4], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "            plt.plot([0.7, 0.7], [-.3, 2.4], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "            plt.xticks([0.2, 0.5, 0.7],)\n",
    "        else:\n",
    "            plt.plot([.5, .5], [-.3, 2.4], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "            plt.plot([0, .5], [2.4, 2.4], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "            plt.xticks([0.5],)\n",
    "        plt.xlim([0, 1.05])\n",
    "        plt.ylim([-.3,9])\n",
    "        plt.xlabel('Ability', fontsize = fsz)\n",
    "        plt.ylabel('Exp. Error', fontsize = fsz)\n",
    "        plt.yticks([2.4])\n",
    "    plt.legend(fontsize = fsz - 2)\n",
    "    plt.savefig(save_name[n], bbox_inches = 'tight',\n",
    "    pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_2 = np.array([[0.4, 0.5],\n",
    "                     [0.4, 1.],\n",
    "                     [0.4, 2.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(params_2):\n",
    "    responses = []\n",
    "    for ability in abilities:\n",
    "        responses.append(beta_irt(ability, param[0], param[1]))\n",
    "    plt.plot(abilities, responses, c = colors[i], label = 'aj = {}'.format(str(param[1])))\n",
    "plt.plot([0.4, 0.4], [-.05, .5], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "plt.plot([-.05, 0.4], [.5, .5], linestyle = '--', c = line_sty, linewidth = 1)\n",
    "plt.xticks([0, 0.4, 1])\n",
    "plt.yticks([0, 0.5, 1])\n",
    "plt.xlim([-.05, 1.05])\n",
    "plt.ylim([-.05, 1.05])\n",
    "plt.xlabel('Ability', fontsize = fsz)\n",
    "plt.ylabel('Transf. Norm. Error', fontsize = fsz)\n",
    "plt.legend(fontsize = fsz - 2)\n",
    "plt.savefig('BIRT_REG', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'auto93'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "path = './Results_IRT/'+name+'/'\n",
    "foldernames = glob.glob(path+'*/')\n",
    "keys = list(map(lambda x: int(x[:-1].split('_')[-1]), foldernames))\n",
    "keys = sorted(range(len(keys)), key=lambda k: keys[k])\n",
    "foldernames = list(map(lambda k: foldernames[k], keys))\n",
    "names = list(map(lambda x: x.split('/')[-2], foldernames))\n",
    "max_std = int(names[-1].split('_')[-1])\n",
    "cmap1 = sns.cubehelix_palette(rot=-.5,light=1.5,dark=-.5,as_cmap=True)\n",
    "fsz = 15\n",
    "mdls = ['LR', 'Bayes', ' SVR(Lin)', ' SVR(Rbf)', 'KNR', 'DT', 'RF', 'AdaB', 'MLP100', 'MLP50-50', 'Avg', 'Opt', 'Wrs']\n",
    "chosen_i = [55, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/SELECTED/' + name + '.csv', na_values=['?'])\n",
    "df = df.dropna()\n",
    "# X = df.iloc[:, 0].values.reshape(-1,1)\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "inst = ['a', 'b']\n",
    "\n",
    "# Principal component analysis\n",
    "pca = PCA(n_components= 1)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "X_train = sc_x.fit_transform(X_train)\n",
    "X_test = sc_x.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = sc_y.transform(y_test.reshape(-1,1))\n",
    "    \n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "plt.scatter(X_train, y_train, label = 'Train',cmap = cmap1, edgecolor='k')\n",
    "plt.scatter(X_test, y_test, label = 'Test', c='red',cmap = cmap1, edgecolor='k', marker='s')\n",
    "\n",
    "# for i, pt in enumerate(chosen_i):\n",
    "#     plt.plot([X_test[pt],X_test[pt] - 0.5], [y_test[pt], y_test[pt] + .02*pt], c='black')\n",
    "#     plt.text(x = X_test[pt] -.7 if i == 0 else X_test[pt] - .7, y = y_test[pt]+ 1.3 if i == 0 else y_test[pt]+ 0.3, s='Inst. {}' .format(inst[i]), fontsize = fsz)\n",
    "plt.ylabel('y', fontsize= fsz)\n",
    "plt.xlabel('x', fontsize= fsz)\n",
    "plt.legend(fontsize = fsz)\n",
    "plt.savefig('./Results_IRT/' + name + '/train_test_dataset.png', bbox_inches = 'tight',\n",
    "    pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for i, df in enumerate(foldernames):\n",
    "    path = df\n",
    "    filenames = glob.glob(path + \"/*.csv\")\n",
    "    \n",
    "    filenames.sort()\n",
    "\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        dfs.append(pd.read_csv(filename))\n",
    "        \n",
    "    all_files.append(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilities = np.zeros((len(mdls), len(foldernames)))\n",
    "noises = np.zeros((len(foldernames), len(all_files[0][-1])))\n",
    "errors = np.zeros((len(foldernames), len(all_files[0][-1]), len(mdls) - 3))\n",
    "responses = np.zeros((len(foldernames), len(all_files[0][-1]), len(mdls)))\n",
    "params = np.zeros((len(foldernames), len(all_files[0][-1]), 2))\n",
    "test = np.zeros((len(foldernames), len(all_files[0][-1]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(all_files):\n",
    "    abilities[:, i] = data[1].iloc[:, -1].values\n",
    "    errors[i] = data[0].values\n",
    "    responses[i] = data[2].values\n",
    "    params[i] = data[3].values\n",
    "    noises[i] = data[-2].values.reshape(1,-1)[0]\n",
    "    if all_files[0][-1].shape[1] > 2:\n",
    "        # Principal component analysis\n",
    "        test[i][:, 0] = X_test.reshape(1,-1)[0]\n",
    "        test[i][:, 1] = data[-1].iloc[:, -1].values[:]\n",
    "    else:\n",
    "        test[i] = data[-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response (Itens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise x MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.zeros((len(all_files), 10))\n",
    "norm_errors = np.zeros((len(all_files), 13))\n",
    "for i in range(21):\n",
    "    mae[i] = np.absolute(errors[i]).mean(axis=0)\n",
    "    norm_errors[i] = ((1-responses[i])/responses[i]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for j, model in enumerate(mdls):\n",
    "    if j < 10:\n",
    "        plt.plot(list(range(21)), norm_errors[:, j], linewidth=0.9, label=model, marker='s',)\n",
    "    else:\n",
    "        plt.plot(list(range(21)), norm_errors[:, j], linewidth=0.9, label=model, marker='o', linestyle='--')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "\n",
    "# plt.xlim([-.1,20.1])\n",
    "# plt.ylim([-0.1, 8.0])\n",
    "\n",
    "plt.ylabel('Absolute Error', fontsize = fsz)\n",
    "plt.xlabel('Noise level', fontsize = fsz)\n",
    "plt.legend(loc = 'best', ncol = 4, fontsize = fsz-2)\n",
    "plt.savefig('./Results_IRT/' + name + '/norm_noise_target.png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise x Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for j, model in enumerate(mdls):\n",
    "    if j>9:\n",
    "        plt.plot(list(range(21)), abilities[j, :], linewidth=0.9, label=model, marker='o', linestyle = '--')\n",
    "    else:\n",
    "        plt.plot(list(range(21)), abilities[j, :], linewidth=0.9, label=model, marker='s')\n",
    "plt.xticks(range(0, 21, 2))\n",
    "plt.xlim([-.1,20.1])\n",
    "plt.ylim([0.3,.9])\n",
    "\n",
    "plt.ylabel('Ability', fontsize=fsz)\n",
    "plt.xlabel('Noise level', fontsize = fsz)\n",
    "plt.legend(loc='best', ncol=4, fontsize=fsz-2)\n",
    "plt.savefig('./Results_IRT/' + name + '/noise_ability_target.png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plts = ['Original', '50% Noise', '100% Noise']\n",
    "plot = ['Difficulty', 'Discrimination']\n",
    "noises_i = [0, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18,3))\n",
    "scale = 0\n",
    "for i, noise_i in enumerate(noises_i):\n",
    "    values = all_files[noise_i][2].values.reshape(-1,1)\n",
    "    sns.distplot(values, ax= axes[i])\n",
    "    current_scale = axes[i].get_ylim()[1] - axes[i].get_ylim()[0]\n",
    "    if current_scale > scale:\n",
    "        scale = current_scale\n",
    "        y_lim = axes[i].get_ylim()\n",
    "    axes[i].set_title(plts[i])\n",
    "    axes[i].set_xlabel('Response value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "for ax in axes:\n",
    "    ax.set_ylim(y_lim)\n",
    "    ax.set_xlim([0, 1.05])\n",
    "fig.savefig('./Results_IRT/'+name+'/hists_target.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in noises_i[1:]:\n",
    "    plt.scatter(test[i][:, 0], test[i][:, 1], c= noises[i], cmap=cmap1, edgecolors='k')\n",
    "    plt.ylim([test[-1][:,1].min()*1.2, test[-1][:,1].max()*1.2])\n",
    "#     plt.xticks(range(-2,3))\n",
    "    plt.savefig('./Results_IRT/' + name + '/y_noise_{}.png'.format(str(i)), bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0\n",
    "\n",
    "models = [LinearRegression(), BayesianRidge(), svm.SVR(kernel= 'linear'), svm.SVR(kernel = 'rbf', gamma= 'scale', C = 5),\\\n",
    "    KNeighborsRegressor(), DecisionTreeRegressor(), RandomForestRegressor(),\\\n",
    "    AdaBoostRegressor(), MLPRegressor(max_iter=1000, solver= 'lbfgs'), MLPRegressor(hidden_layer_sizes= (50,50), solver = 'lbfgs', max_iter=500, activation='logistic')]\n",
    "\n",
    "model_pred = np.zeros((len(models), len(y_test)))\n",
    "for m, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    model_pred[m] = model.predict(X_test).reshape(1,-1)\n",
    "\n",
    "Xsort_i = np.argsort(X_test.reshape(1,-1))\n",
    "\n",
    "sns.set_context('paper')\n",
    "\n",
    "for i, title in enumerate(plot):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "        \n",
    "    c = params[0][:, i]\n",
    "    plt.scatter(X_test, y_test, c = c.reshape(-1,1), cmap = cmap1, edgecolor='k',s=40)\n",
    "    \n",
    "    for j, m in enumerate(model_pred):\n",
    "        plt.plot(X_test[Xsort_i][0], m[Xsort_i].reshape(-1,1), linewidth = 0.5, label = mdls[j])\n",
    "\n",
    "    plt.hlines(y = y_test.mean(), xmin = X_test.min(), xmax = X_test.max(), color = 'black')\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    plt.savefig('./Results_IRT/' + name + '/param_'+ title +'_pred.png', bbox_inches = 'tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0\n",
    "fig, axes = plt.subplots(2, 3, figsize=(21,10))\n",
    "\n",
    "for i, title in enumerate(plot):\n",
    "    for j,noise in enumerate(noises_i):        \n",
    "        axes[i,j].set_ylim([1.1*test[-1][:, 1].min(), 1.1*test[-1][:, 1].max()])\n",
    "#         axes[i,j].set_ylim([.85*test[-1][:, 1].min(), 1.15*test[-1][:, 1].max()])    \n",
    "        \n",
    "        c = params[noise][:, i]\n",
    "        \n",
    "        sns.set_context('paper')\n",
    "\n",
    "        axes[i, j].scatter(test[noise][:, 0], test[noise][:, 1], c = c, cmap = cmap1, edgecolor='k',s=30)\n",
    "        \n",
    "        axes[i,j].set_xlabel('x (' + plts[j]+')')\n",
    "        axes[i,j].set_ylabel('y')\n",
    "        axes[i,j].set_title(title + (' (ẟ)' if i == 0 else ' (a)'))\n",
    "plt.savefig('./Results_IRT/' + name + '/params_noise_target.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difficulty/ Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsort_i = np.argsort(test[0][:, 0].reshape(1,-1))\n",
    "X_test = test[0][:, 0]\n",
    "p_mean = params.mean(axis=0)\n",
    "p_std = params.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x = pd.Series(params[0][:, 0])\n",
    "ma = p_x.rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, param in enumerate(plot):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    x = X_test[Xsort_i].reshape(1,-1)[0]\n",
    "    pmean = pd.Series(params[0, Xsort_i, i][0])\n",
    "    pmean1 = pd.Series(params[10, Xsort_i, i][0])\n",
    "    pmean2 = pd.Series(params[20, Xsort_i, i][0])\n",
    "#     pstd = pd.Series(p_std[Xsort_i, i][0])\n",
    "    \n",
    "#     axes[i].fill_between(x, y1 = (pmean - 2*pstd).rolling(window=4).mean(), y2 = (pmean + 2*pstd).rolling(window=4).mean(), alpha=0.2)\n",
    "    plt.plot(x, pmean.rolling(window=6, min_periods =2).mean(), label = 'Original dataset', linewidth=1.5)\n",
    "    plt.plot(x, pmean1.rolling(window=6, min_periods =2).mean(), label = '$σ_y$ = 0.25', linewidth=1.5)\n",
    "    plt.plot(x, pmean2.rolling(window=6, min_periods =2).mean(), label = '$σ_y$ = 0.5', linewidth=1.5)\n",
    "    \n",
    "#     axes[i].plot(x, (pmean - 2*pstd).rolling(window=4).mean(), linewidth = 0.5, c='black')\n",
    "#     axes[i].plot(x, (pmean + 2*pstd).rolling(window=4).mean(), linewidth = 0.5, c='black')\n",
    "    plt.xlabel('x', fontsize=fsz)\n",
    "    plt.xlim([x[0], x[-1]])\n",
    "    plt.ylabel(param, fontsize=fsz)\n",
    "    plt.xticks(fontsize=fsz-2)\n",
    "    plt.yticks(fontsize=fsz-2)\n",
    "# plt.savefig('./Results_IRT/' + name + '/params_x.png')\n",
    "    plt.legend(fontsize=fsz-2)\n",
    "#     plt.show()\n",
    "    \n",
    "    plt.savefig('./Results_IRT/'+name+'/'+ param + '_x_target.png', bbox_inches = 'tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lower noise\n",
    "scale = 0\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,12))\n",
    "\n",
    "for i, title in enumerate(plot):\n",
    "    for j,noise in enumerate(noises_i[1:]):\n",
    "        if i == 0:\n",
    "            lim = np.array([0,1])\n",
    "        else:\n",
    "            lim = np.array([-0.2, 1.2])\n",
    "        \n",
    "        axes[i,j].set_xlim(lim)\n",
    "        axes[i,j].set_ylim(lim)\n",
    "        axes[i,j].plot([lim[0],lim[1]], [lim[0], lim[1]], linewidth=0.2, c='black')        \n",
    "        \n",
    "        sns.set_context('paper')\n",
    "\n",
    "        axes[i,j].text(x = lim[0], y = lim[0], s='Corr = %.2f' %(spearmanr(a = params[0][:, i], b = params[noise][:, i])[0]))\n",
    "        axes[i, j].scatter(params[0][:, i], params[noise][:, i], c = noises[noise], cmap = cmap1, edgecolor='k',s=30)\n",
    "\n",
    "        axes[i,j].set_xlabel(\"Original data\")\n",
    "        axes[i,j].set_ylabel(plts[j+1])\n",
    "        axes[i,j].set_title(title)\n",
    "fig.savefig('./Results_IRT/'+name+'/parameters_target.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 3, figsize=(16,5))\n",
    "for i, noise in enumerate(noises_i):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    c = np.absolute(noises[i])\n",
    "\n",
    "    plt.scatter(params[noise][:,0], params[noise][:,1], c = c, cmap = cmap1, edgecolor='k',s=30)\n",
    "    plt.text(x = 0, y = -.2, s='Corr = %.2f' %(spearmanr(a = params[noise][:,0], b= params[noise][:,1])[0]))\n",
    "\n",
    "#     plt.title(plts[i])\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([-0.2, 1.2])\n",
    "    plt.xlabel('Difficulty', fontsize=fsz)\n",
    "    plt.ylabel('Discrimination',fontsize=fsz)\n",
    "    plt.savefig('./Results_IRT/'+name+'/dif_disc_' + str(noise) + '_target.png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,10))\n",
    "for h, param in enumerate(['Diff', 'Discrim']):\n",
    "    for i, noise in enumerate(noises_i[1:]):\n",
    "        axes[h, i].scatter(noises[noise], (params[noise][:, h] - params[0][:, h]), edgecolor='k',s=30)\n",
    "        axes[h, i].set_ylim([-1., 1.])\n",
    "        axes[h, i].set_xlim([0, noises[-1].max() + 0.1])\n",
    "        axes[h, i].text(x = 0, y = -1, s='Corr = %.2f' %(spearmanr(a = noises[noise], b = (params[noise][:, h] - params[0][:, h]))[0]))\n",
    "\n",
    "        axes[h, i].set_xlabel('|Noise|')\n",
    "        axes[h, i].set_ylabel('Δ '+param+' ('+plts[i+1]+' - Original)')\n",
    "fig.savefig('./Results_IRT/'+name+'/param_noise_target.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = [0.3, 0.8]\n",
    "std = [0.25, 0.5]\n",
    "for i, noise in enumerate(noises_i[1:]):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for j, mdl in enumerate(mdls):\n",
    "        if j < 10:\n",
    "            plt.scatter(abilities[j, 0], abilities[j, noise], s = 90, label = mdl, edgecolor='k')\n",
    "        else:\n",
    "            plt.scatter(abilities[j, 0], abilities[j, noise], s = 90, label = mdl, edgecolor='k', marker = 's')\n",
    "    plt.xlim(lim)\n",
    "    plt.ylim(lim)\n",
    "    plt.xlabel('Ability (Original dataset)', fontsize=fsz)\n",
    "    plt.ylabel('Ability (Noisy data)', fontsize=fsz)\n",
    "    plt.plot(lim, lim, linewidth=0.2, c='black')\n",
    "    plt.legend(fontsize = fsz-2)\n",
    "    plt.xticks(fontsize = fsz-2)\n",
    "    plt.yticks(fontsize = fsz-2)\n",
    "    plt.savefig('./Results_IRT/'+name+'/ability_{}_target.png'.format(str(i)), bbox_inches = 'tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 3, figsize=(16,5))\n",
    "for i, noise in enumerate(noises_i):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    c = np.absolute(noises[noise])\n",
    "    mean_error = np.absolute(errors[noise]).mean(axis = 1)\n",
    "    diff = params[noise][:, 0]\n",
    "    plt.scatter(diff,mean_error, c= c, cmap = cmap1, edgecolor='k',s=30)\n",
    "#     plt.text(x = 0, y = 0, s='Mean = %.2f Std = %.2f Corr = %.2f' %(mean_error.mean(), mean_error.std(), spearmanr(a = diff, b = mean_error)[0]), fontsize=10)\n",
    "    plt.xlabel('Difficulty', fontsize=fsz)\n",
    "    plt.ylabel('Average Error (Instance)', fontsize=fsz)\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0, 1.2*np.absolute(errors[-1]).mean(axis = 1).max()])\n",
    "#     plt.title(plts[i])\n",
    "    plt.savefig('./Results_IRT/'+name+'/diff_error_' + str(noise) + '_target.png', bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "for i, noise in enumerate(noises_i[1:]):\n",
    "    mean_error = np.absolute(errors[noise]).mean(axis = 1)\n",
    "    axes[i].scatter(noises[noise], mean_error, edgecolor='k',s=30)\n",
    "    axes[i].text(x = 0, y = 0, s='Corr = %.2f' %(spearmanr(a = noises[noise], b = mean_error)[0]), fontsize=10)\n",
    "    axes[i].set_xlabel('|Noise|')\n",
    "    axes[i].set_ylabel('Mean Error (Instance)')\n",
    "    axes[i].set_xlim([-0.01, 1.5])\n",
    "    axes[i].set_ylim([0, 1.05*np.absolute(errors[-1]).mean(axis = 1).max()])\n",
    "    axes[i].set_title(plts[i+1])\n",
    "fig.savefig('./Results_IRT/'+name+'/noise_error_target.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h, param in enumerate(plot):\n",
    "    sns.set_context('paper')\n",
    "    scale = 0\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18,2))\n",
    "    for i, noise in enumerate(noises_i):\n",
    "        values = params[noise][:, h]\n",
    "        sns.distplot(values,bins=100,ax=axes[i])\n",
    "        sns.distplot(values, ax= axes[i])\n",
    "        current_scale = axes[i].get_ylim()[1] - axes[i].get_ylim()[0]\n",
    "        if current_scale > scale:\n",
    "            scale = current_scale\n",
    "            y_lim = axes[i].get_ylim()\n",
    "        axes[i].set_title(param + ' (' + plts[i] + ')')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(y_lim)\n",
    "        ax.set_xlim([-0.1, 1.2])\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    fig.savefig('./Results_IRT/'+name+'/hists_' + param + '_target.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.lexsort((params[0,:,0], params[0,:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params[0, ind,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# +Diff+Disc/ -Diff-Disc/ -Diff+Disc/ +Diff-Disc\n",
    "chosen_i = [55, 0, 15, 37]\n",
    "ab = np.linspace(0.0001, 0.9999, 200)\n",
    "sub_noise = ['Noise free', '50% Noise', '100% Noise']\n",
    "\n",
    "for j in (chosen_i):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    par = params[0, j, :]\n",
    "    diff = par[0]\n",
    "    disc = par[1]\n",
    "    E = [beta_irt(x, diff, disc) for x in ab]\n",
    "    middle = np.where(np.array(E)>0.499)[0][:2]\n",
    "    p1 = [ab[middle[0]], E[middle[0]]]\n",
    "    p2 = [ab[middle[1]], E[middle[1]]]\n",
    "    newline(p1,p2)\n",
    "    slope = (E[middle[1]] - E[middle[0]])/(ab[middle[1]] - ab[middle[0]])\n",
    "    plt.text(p2[0], p2[1], 'slope = '+str(round(slope, 3)),fontsize=15)\n",
    "    plt.plot(ab, E,)\n",
    "    plt.plot([ab[middle[0]], ab[middle[0]]],[0, E[middle[0]]], '--r')\n",
    "    plt.plot([0, ab[middle[0]]],[E[middle[0]], E[middle[0]]], '--r')\n",
    "    plt.scatter(abilities[:, 0], responses[0, j, :], marker= 'x', c = 'red')\n",
    "    plt.ylabel('Response', fontsize=fsz)\n",
    "    plt.xlabel('Ability', fontsize=fsz)\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "#     plt.title('Instance ' + str(j))\n",
    "#         plt.legend()\n",
    "    plt.savefig('./Results_IRT/'+name+'_TARGET/instance_' + str(j) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +Diff+Disc/ -Diff-Disc/ -Diff+Disc/ +Diff-Disc\n",
    "ab = np.linspace(0.0000000000001, 0.999999999999, 50000)\n",
    "sub_noise = ['Noise free', '50% Noise', '100% Noise']\n",
    "\n",
    "for j in (chosen_i):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    par = params[0, j, :]\n",
    "    diff = par[0]\n",
    "    disc = par[1]\n",
    "    E = [beta_irt(x, diff, disc) for x in ab]\n",
    "    E = list(map(lambda res: (1-res)/res, E))\n",
    "#     middle = np.where(np.array(E)>0.499)[0][:2]\n",
    "#     p1 = [ab[middle[0]], E[middle[0]]]\n",
    "#     p2 = [ab[middle[1]], E[middle[1]]]\n",
    "#     newline(p1,p2)\n",
    "#     slope = (E[middle[1]] - E[middle[0]])/(ab[middle[1]] - ab[middle[0]])\n",
    "#     plt.text(p2[0], p2[1], 'slope = '+str(round(slope, 3)),fontsize=15)\n",
    "    plt.plot(ab, E, linewidth=2.5, label = 'Difficulty = {0:.2f}\\n\\nDiscrimination = {1:.2f}'.format((diff), (disc)))\n",
    "    response = responses[0][j, :]\n",
    "    plt.scatter(abilities[:, 0], (1-response)/response, marker='x', c='red', s=50)\n",
    "#     plt.plot([ab[middle[0]], ab[middle[0]]],[0, E[middle[0]]], '--r')\n",
    "#     plt.plot([0, ab[middle[0]]],[E[middle[0]], E[middle[0]]], '--r')\n",
    "#     plt.scatter(abilities[:, 0], responses[0, j, :], marker= 'x', c = 'red')\n",
    "    plt.ylabel('Normalised Error', fontsize=fsz+2)\n",
    "    plt.xlabel('Ability', fontsize=fsz+2)\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.5, 16])\n",
    "    plt.legend(fontsize = fsz, handlelength=0, handletextpad=0, fancybox=True)\n",
    "#     plt.title('Instance ' + str(j))\n",
    "#         plt.legend()\n",
    "    plt.savefig('./Results_IRT/'+name+'/err_instance_' + str(j) + '_target.png', bbox_inches = 'tight',\n",
    "    pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentual variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors = np.absolute(errors).mean(axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ab = np.zeros((len(abilities)-3, abilities.shape[1]-1))\n",
    "var_ab.shape\n",
    "var_error = np.zeros((len(abilities)-3, abilities.shape[1]-1))\n",
    "var_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, noise_i in enumerate(range(1, abilities.shape[1])):\n",
    "    var_ab[:, i] = 100*np.absolute(abilities[:-3, noise_i] - abilities[:-3, 0])/abilities[:-3, 0]\n",
    "    var_error[:, i] = 100*np.absolute(mean_errors[:, noise_i] - mean_errors[:, 0])/mean_errors[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(var_ab <= var_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((var_ab - var_error).T, index=np.arange(1,21), columns=mdls[:-3]).round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste t-pareado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_rel(a=var_ab.reshape(-1,1)[:,0], b=var_error.reshape(-1,1)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_2samp(data1=var_ab.reshape(-1,1)[:,0], data2=var_error.reshape(-1,1)[:,0],alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = sns.cubehelix_palette(10, start=2, rot=0, dark=0, light=.95, reverse=True)\n",
    "plt.subplots(figsize=(12,7))\n",
    "s = sns.heatmap(data= df, cmap=cm, annot=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

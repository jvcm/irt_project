{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from irt import IRTModel\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "# from beta_irt.visualization.plots import newline\n",
    "# from beta_irt.visualization.plots import plot_parameters\n",
    "# from irt import beta_irt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "import glob\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from beta_irt.visualization.plots import plot_parameters\n",
    "from scipy.interpolate import spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "path_data = './data/'\n",
    "path_uci = './data/UCI - 45/'\n",
    "\n",
    "# Read csv\n",
    "data = pd.read_csv(path_uci + name + '.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "# Parameters\n",
    "rd = 42\n",
    "\n",
    "# Variable selection\n",
    "X = data.iloc[:, 0].values.reshape(-1,1)\n",
    "y = data.iloc[:, 1]\n",
    "\n",
    "# Split data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = rd)\n",
    "\n",
    "# # Principal component analysis\n",
    "# pca = PCA(n_components= 1)\n",
    "# X_train = pca.fit_transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "# Standard scale\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "path = './Results_IRT/'+name+'/'\n",
    "foldernames = glob.glob(path+'*/')\n",
    "keys = list(map(lambda x: int(x[:-1].split('_')[-1]), foldernames))\n",
    "keys = sorted(range(len(keys)), key=lambda k: keys[k])\n",
    "foldernames = list(map(lambda k: foldernames[k], keys))\n",
    "names = list(map(lambda x: x.split('/')[-2], foldernames))\n",
    "max_std = int(names[-1].split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for i, df in enumerate(foldernames):\n",
    "    path = df\n",
    "    filenames = glob.glob(path + \"/*.csv\")\n",
    "    \n",
    "    filenames.sort()\n",
    "\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        dfs.append(pd.read_csv(filename))\n",
    "        \n",
    "    all_files.append(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls = ['LR', 'Bayes', 'SVR(Linear)', 'SVR(Rbf)', 'KNR', 'DT', 'RF', 'AdaB', 'MLP (100)', 'MLP (50-50)', 'Average', 'Optimal', 'Worst']\n",
    "abilities = np.zeros((len(mdls), len(foldernames)))\n",
    "noises = np.zeros((len(foldernames), len(all_files[0][-1])))\n",
    "errors = np.zeros((len(foldernames), len(all_files[0][-1]), len(mdls) - 3))\n",
    "responses = np.zeros((len(foldernames), len(all_files[0][-1]), len(mdls)))\n",
    "params = np.zeros((len(foldernames), len(all_files[0][-1]), 2))\n",
    "test = np.zeros((len(foldernames), len(all_files[0][-1]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(all_files):\n",
    "    abilities[:, i] = data[1].iloc[:, -1].values\n",
    "    errors[i] = data[0].values\n",
    "    responses[i] = data[2].values\n",
    "    params[i] = data[3].values\n",
    "    noises[i] = data[-2].values.reshape(1,-1)[0]\n",
    "    test[i] = data[-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise x MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.zeros((len(all_files), 10))\n",
    "for i in range(20):\n",
    "    mae[i] = np.absolute(errors[i]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 9))\n",
    "for j, model in enumerate(mdls[:10]):\n",
    "    plt.plot(list(range(20)), mae[:, j], linewidth=0.9, label=model, marker='s',)\n",
    "plt.xticks(range(0, 20, 2))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width*0.65, box.height])\n",
    "legend_x = 1\n",
    "legend_y = 0.5\n",
    "\n",
    "plt.ylabel('Mean Absolute Error (MAE)')\n",
    "plt.xlabel('Noise level')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(legend_x, legend_y))\n",
    "plt.savefig('./Results_IRT/' + name + '/mae_noise.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise x Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 9))\n",
    "for j, model in enumerate(mdls):\n",
    "    if j>9:\n",
    "        plt.plot(list(range(20)), abilities[j, :], linewidth=0.9, label=model, marker='s', linestyle = '--')\n",
    "    else:\n",
    "        plt.plot(list(range(20)), abilities[j, :], linewidth=0.9, label=model, marker='o')\n",
    "plt.xticks(range(0, 20, 2))\n",
    "plt.xlim([-.1,19.1])\n",
    "plt.ylim([0.3,0.8])\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width*0.65, box.height])\n",
    "legend_x = 1\n",
    "legend_y = 0.5\n",
    "\n",
    "plt.ylabel('Ability')\n",
    "plt.xlabel('Noise level')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(legend_x, legend_y))\n",
    "plt.savefig('./Results_IRT/' + name + '/noise_ability.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plts = ['Original', 'Noise 1', 'Noise 2']\n",
    "noises_i = [0, 9, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18,3))\n",
    "scale = 0\n",
    "for i, noise_i in enumerate(noises_i):\n",
    "    values = all_files[noise_i][2].values.reshape(-1,1)\n",
    "    sns.distplot(values, ax= axes[i])\n",
    "    current_scale = axes[i].get_ylim()[1] - axes[i].get_ylim()[0]\n",
    "    if current_scale > scale:\n",
    "        scale = current_scale\n",
    "        y_lim = axes[i].get_ylim()\n",
    "    axes[i].set_title(plts[i])\n",
    "    axes[i].set_xlabel('Response value')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "for ax in axes:\n",
    "    ax.set_ylim(y_lim)\n",
    "fig.savefig('./Results_IRT/'+name+'/hists.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRT Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(noises_i):\n",
    "    concat = np.concatenate((test[n][:, 0].reshape(-1,1), test[n][:, 1].reshape(-1,1)), axis = 1)\n",
    "    f = plot_parameters(concat, delta = params[n][:, 0], a = params[n][:, 1], xlim = [0.85*test[noises_i[-1]][:, 0].min(), 1.15*test[noises_i[-1]][:, 0].max()])\n",
    "    plt.savefig('./Results_IRT/' + name + '/params_'+ str(i) +'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difficulty/ Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = [\"Difficulty\", \"Discrimination\"]\n",
    "Xsort_i = np.argsort(X_test.reshape(1,-1))\n",
    "p_mean = params.mean(axis=0)\n",
    "p_std = params.std(axis=0)\n",
    "cmap1 = sns.cubehelix_palette(rot=-.5,light=1.5,dark=-.5,as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "for i, param in enumerate(plot):\n",
    "    x = X_test[Xsort_i].reshape(1,-1)[0]\n",
    "    pmean = p_mean[Xsort_i, i][0]\n",
    "    pstd = p_std[Xsort_i, i][0]\n",
    "    \n",
    "    axes[i].fill_between(x, y1 = pmean - 2*pstd, y2 = pmean + 2*pstd, alpha=0.2)\n",
    "    axes[i].plot(x, pmean)\n",
    "    axes[i].plot(x, pmean - 2*pstd, linewidth = 0.5, c='black')\n",
    "    axes[i].plot(x, pmean + 2*pstd, linewidth = 0.5, c='black')\n",
    "    axes[i].set_xlabel('X')\n",
    "    axes[i].set_xlim([x[0], x[-1]])\n",
    "    axes[i].set_ylabel(param)\n",
    "plt.savefig('./Results_IRT/' + name + '/params_x.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lower noise\n",
    "scale = 0\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,12))\n",
    "\n",
    "for i, title in enumerate(plot):\n",
    "    for j,noise in enumerate(noises_i[1:]):\n",
    "        if i == 0:\n",
    "            lim = np.array([0,1])\n",
    "        else:\n",
    "            lim = np.array([-0.2, 1.2])\n",
    "        \n",
    "        axes[i,j].set_xlim(lim)\n",
    "        axes[i,j].set_ylim(lim)\n",
    "        axes[i,j].plot([lim[0],lim[1]], [lim[0], lim[1]], linewidth=0.2, c='black')        \n",
    "        \n",
    "        sns.set_context('paper')\n",
    "\n",
    "        axes[i,j].text(x = lim[0], y = lim[0], s='Corr = %.2f' %(spearmanr(a = params[0][:, i], b = params[noise][:, i])[0]))\n",
    "        axes[i, j].scatter(params[0][:, i], params[noise][:, i], c = noises[noise], cmap = cmap1, edgecolor='k',s=30)\n",
    "\n",
    "        axes[i,j].set_xlabel(\"Original data\")\n",
    "        axes[i,j].set_ylabel('Noise ' + str(j+1))\n",
    "        axes[i,j].set_title(title)\n",
    "fig.savefig('./Results_IRT/'+name+'/parameters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16,5))\n",
    "for i, noise in enumerate(noises_i):\n",
    "    c = np.absolute(noises[i])\n",
    "\n",
    "    axes[i].scatter(params[noise][:,0], params[noise][:,1], c = c, cmap = cmap1, edgecolor='k',s=30)\n",
    "    axes[i].set_title(plts[i])\n",
    "    axes[i].set_xlim([0,1])\n",
    "    axes[i].set_ylim([-0.2, 1.2])\n",
    "    axes[i].set_xlabel('Difficulty')\n",
    "    axes[i].set_ylabel('Discrimination')\n",
    "fig.savefig('./Results_IRT/'+name+'/dif_disc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,10))\n",
    "for h, param in enumerate(['Diff', 'Discrim']):\n",
    "    for i, noise in enumerate(noises_i[1:]):\n",
    "        axes[h, i].scatter(noises[noise], (params[noise][:, h] - params[0][:, h]), edgecolor='k',s=30)\n",
    "        axes[h, i].set_ylim([-1., 1.])\n",
    "        axes[h, i].set_xlim([-.2, noises[-1].max() + 0.1])\n",
    "        axes[h, i].text(x = -.2, y = -1, s='Corr = %.2f' %(spearmanr(a = noises[noise], b = (params[noise][:, h] - params[0][:, h]))[0]))\n",
    "\n",
    "        axes[h, i].set_xlabel('|Noise|')\n",
    "        axes[h, i].set_ylabel('Î” '+param+' ('+plts[i+1]+' - Original)')\n",
    "fig.savefig('./Results_IRT/'+name+'/param_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14,6))\n",
    "mdls = mdls = ['LR', 'Bayes', ' SVR(Lin)', ' SVR(Rbf)', 'KNR', 'DT', 'RF', 'AdaB', 'MLP100', 'MLP50-50', 'Avg', 'Opt', 'Wrs']\n",
    "lim = [0.4, 0.7]\n",
    "\n",
    "for i, noise in enumerate(noises_i[1:]):\n",
    "    for j, mdl in enumerate(mdls):\n",
    "        axes[i].scatter(abilities[j, 0], abilities[j, noise], s = 50, label = mdl, edgecolor='k')\n",
    "    axes[i].set_xlim(lim)\n",
    "    axes[i].set_ylim(lim)\n",
    "    axes[i].set_xlabel('Original')\n",
    "    axes[i].set_ylabel('Noise ' + str(i+1))\n",
    "    axes[i].set_title('Ability')\n",
    "    axes[i].plot(lim, lim, linewidth=0.2, c='black')\n",
    "    axes[i].legend()\n",
    "fig.savefig('./Results_IRT/'+name+'/ability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16,5))\n",
    "for i, noise in enumerate(noises_i):\n",
    "    c = np.absolute(noises[noise])\n",
    "    mean_error = np.absolute(errors[noise]).mean(axis = 1)\n",
    "    diff = params[noise][:, 0]\n",
    "    axes[i].scatter(diff,mean_error, c= c, cmap = cmap1, edgecolor='k',s=30)\n",
    "    axes[i].text(x = 0, y = 0, s='Mean = %.2f Std = %.2f Corr = %.2f' %(mean_error.mean(), mean_error.std(), spearmanr(a = diff, b = mean_error)[0]), fontsize=10)\n",
    "    axes[i].set_xlabel('Difficulty')\n",
    "    axes[i].set_ylabel('Mean Error (Instance)')\n",
    "    axes[i].set_xlim([0,1])\n",
    "    axes[i].set_ylim([0, 1.05*np.absolute(errors[-1]).mean(axis = 1).max()])\n",
    "    axes[i].set_title(plts[i])\n",
    "fig.savefig('./Results_IRT/'+name+'/diff_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "for i, noise in enumerate(noises_i[1:]):\n",
    "    mean_error = np.absolute(errors[noise]).mean(axis = 1)\n",
    "    axes[i].scatter(noises[noise], mean_error, edgecolor='k',s=30)\n",
    "    axes[i].text(x = 0, y = 0, s='Corr = %.2f' %(spearmanr(a = noises[noise], b = mean_error)[0]), fontsize=10)\n",
    "    axes[i].set_xlabel('|Noise|')\n",
    "    axes[i].set_ylabel('Mean Error (Instance)')\n",
    "    axes[i].set_xlim([-0.01, 1.5])\n",
    "    axes[i].set_ylim([-0.1, 1.05*np.absolute(errors[-1]).mean(axis = 1).max()])\n",
    "    axes[i].set_title(plts[i+1])\n",
    "fig.savefig('./Results_IRT/'+name+'/noise_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h, param in enumerate(plot):\n",
    "    sns.set_context('paper')\n",
    "    scale = 0\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18,2))\n",
    "    for i, noise in enumerate(noises_i):\n",
    "        values = params[noise][:, h]\n",
    "        sns.distplot(values,bins=100,ax=axes[i])\n",
    "        sns.distplot(values, ax= axes[i])\n",
    "        current_scale = axes[i].get_ylim()[1] - axes[i].get_ylim()[0]\n",
    "        if current_scale > scale:\n",
    "            scale = current_scale\n",
    "            y_lim = axes[i].get_ylim()\n",
    "        axes[i].set_title(param + ' (' + plts[i] + ')')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(y_lim)\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    fig.savefig('./Results_IRT/'+name+'/hists_' + param + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, noise in enumerate(noises_i):\n",
    "    metrics = pd.DataFrame()\n",
    "    metrics['Avg. Response'] = responses[noise][:, :-3].mean(axis = 0)\n",
    "    metrics['Ability'] = abilities[:-3][noise]\n",
    "    metrics['MAE'] = np.absolute(errors[i]).mean(axis = 0)\n",
    "    metrics['MSE'] = (errors[]**2).mean(axis = 0)\n",
    "    print(noise,'\\n',metrics.corr(method = 'spearman'),'\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from irt import IRTModel\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from beta_irt.visualization.plots import newline\n",
    "from beta_irt.visualization.plots import plot_parameters\n",
    "from irt import beta_irt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import edward as ed\n",
    "import glob\n",
    "import time, sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress, load = 'Progress'):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "#     clear_output(wait = True)\n",
    "    text = load + \": [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text, end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################CREATING ALL REGRESSORS##############################\n",
    "\n",
    "models = [LinearRegression(), BayesianRidge()]\n",
    "names = list(map(lambda x: type(x).__name__, models))\n",
    "\n",
    "C=[1,2,3,4,5]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for krn in kernel:\n",
    "    for c in C:\n",
    "        models.append(svm.SVR(kernel= krn, C=c))\n",
    "        names.append('SVR_'+krn[:3] + '_' +str(c))\n",
    "\n",
    "for k in range(2,16):\n",
    "    models.append(KNeighborsRegressor(n_neighbors= k))\n",
    "    names.append('KNR_{}'.format(str(k)))\n",
    "    \n",
    "max_depth = range(2,16)\n",
    "for md in max_depth:\n",
    "    models.append(DecisionTreeRegressor(max_depth = md))\n",
    "    names.append('DT_{}'.format(str(md)))\n",
    "\n",
    "n_estimator = range(20, 60, 10)\n",
    "for md in range(3,12, 2):\n",
    "    for n in n_estimator:\n",
    "        models.append(RandomForestRegressor(n_estimators = n, max_depth = md))\n",
    "        names.append('RF_e{}_md{}'.format(str(n), str(md)))\n",
    "\n",
    "loss = ['linear', 'square', 'exponential']\n",
    "for l in loss:\n",
    "    for n in n_estimator:\n",
    "        models.append(AdaBoostRegressor(n_estimators= n, loss=l))\n",
    "        names.append('AdaB_loss{}_n{}'.format(l[:3], str(n)))\n",
    "\n",
    "archs = [(5,), (10,), (15,), (20,), (30,), (40,), (50,), (60,)]\n",
    "funcs = ['relu', 'logistic']\n",
    "for f in funcs:\n",
    "    for a in archs:\n",
    "        models.append(MLPRegressor(hidden_layer_sizes=a, activation=f))\n",
    "        names.append('MLP_hls{}_f{}' .format(str(a[0]), f[:3]))\n",
    "\n",
    "names = names + ['Average', 'Optimal', 'Worst']\n",
    "        \n",
    "# Parameters\n",
    "rd = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Data set 1 >>>> disclosurez\n",
      "> Training models\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-358221ddffe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# RESPONSES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'irt_data_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m#-------------------------------------Clean-Files-------------------------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             mgr = self._init_mgr(data, axes=dict(index=index, columns=columns),\n\u001b[0;32m--> 390\u001b[0;31m                                  dtype=dtype, copy=copy)\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_init_mgr\u001b[0;34m(self, mgr, axes, dtype, copy)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 mgr = mgr.reindex_axis(axe,\n\u001b[1;32m    149\u001b[0m                                        \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                                        copy=False)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# make a copy if explicitly requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_axis\u001b[0;34m(self, new_index, axis, method, limit, fill_value, copy)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         return self.reindex_indexer(new_index, indexer, axis=axis,\n\u001b[0;32m-> 1196\u001b[0;31m                                     fill_value=fill_value, copy=copy)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     def reindex_indexer(self, new_axis, indexer, axis, fill_value=None,\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "##############################READING ALL DATASETS##############################\n",
    "\n",
    "selected = './data/SELECTED/'\n",
    "dbs = glob.glob(selected + '*.csv')\n",
    "\n",
    "for d, db in enumerate(dbs):\n",
    "    print('\\n------------------------------------------------------------\\n')\n",
    "\n",
    "    # Creating folders   \n",
    "    name = db.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    print('Data set ' + str(d + 1) + ' >>>> ' + name)\n",
    "    \n",
    "    if not os.path.isdir('./beta_irt/results/'+ name):\n",
    "        os.system('mkdir ./beta_irt/results/'+ name)\n",
    "    \n",
    "    # Read file\n",
    "    df = pd.read_csv(db, na_values=['?'])\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    #Variable selection\n",
    "    if df.shape[1] > 2:\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "        \n",
    "        # Principal component analysis\n",
    "#         pca = PCA(n_components= 1)\n",
    "#         X_train = pca.fit_transform(X_train)\n",
    "#         X_test = pca.transform(X_test)\n",
    "    else: \n",
    "        X = df.iloc[:, 0].values.reshape(-1,1)\n",
    "        y = df.iloc[:, -1].values\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = rd)\n",
    "    \n",
    "    # Standard scale\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    \n",
    "    sc_y = StandardScaler()\n",
    "    y_train = sc_y.fit_transform(y_train.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    y_test = sc_y.transform(y_test.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    \n",
    "    print('> Training models')\n",
    "    # Generate abilities/parameters for BIRT and other info.\n",
    "    Irt = IRTModel(models= models)\n",
    "    Irt.fit(X_train = X_train, y_train = y_train)\n",
    "\n",
    "    # Folders\n",
    "    path = './beta_irt/results/'\n",
    "    folder = name + '/'\n",
    "\n",
    "    #-------------------------------------Generate-BIRT-------------------------------------#\n",
    "\n",
    "    responses = np.zeros((len(X_test), len(models) + 3))\n",
    "\n",
    "    rep = 40\n",
    "    for itr in range(rep):\n",
    "        # Generate IRT matrix\n",
    "        Irt.irtMatrix(X_test= X_test, y_test= y_test, normalize= True, base_models= True, name= name, rd= rd)\n",
    "        responses += Irt.irt_matrix\n",
    "\n",
    "        name_ = name + '_s' + str(len(y_test)) + '_f0_sd' + str(rd)\n",
    "\n",
    "\n",
    "    responses /= rep\n",
    "\n",
    "    # Move files to folder    \n",
    "    output = './Results_IRT/IRT_data/'\n",
    "    if not os.path.isdir(output):\n",
    "        os.system('mkdir '+ output)\n",
    "    if not os.path.isdir(output):\n",
    "        os.system('mkdir ' + output)\n",
    "\n",
    "    # RESPONSES\n",
    "    irt_df = pd.DataFrame(data= responses)\n",
    "    irt_df.columns = names\n",
    "    irt_df.to_csv(output + 'irt_data_' + name_ + '.csv', index=False)\n",
    "\n",
    "    #-------------------------------------Clean-Files-------------------------------------#\n",
    "    \n",
    "    os.system('rm ./beta_irt/*.csv')\n",
    "    os.system('rm ' +path + folder + '*.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(output + 'irt_data_' + name_ + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

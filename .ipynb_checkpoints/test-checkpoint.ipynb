{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from irt import IRTModel\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, BayesianRidge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from beta_irt.visualization.plots import newline\n",
    "from beta_irt.visualization.plots import plot_parameters\n",
    "from irt import beta_irt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "from matplotlib import gridspec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import edward as ed\n",
    "import glob\n",
    "import time, sys\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################CREATING ALL REGRESSORS##############################\n",
    "\n",
    "models = [LinearRegression(), BayesianRidge(), svm.SVR(kernel= 'linear'), svm.SVR(kernel = 'rbf', gamma= 'scale', C = 5),\\\n",
    "     KNeighborsRegressor(), DecisionTreeRegressor(), RandomForestRegressor(),\\\n",
    "          AdaBoostRegressor(), MLPRegressor(max_iter=1000, solver= 'lbfgs'), MLPRegressor(hidden_layer_sizes= (50,50), solver = 'lbfgs', max_iter=500, activation='logistic')]\n",
    "\n",
    "names = list(map(lambda x: type(x).__name__, models))\n",
    "names = names + ['Average', 'Optimal', 'Worst']\n",
    "\n",
    "n_synth_models = 3\n",
    "        \n",
    "# Parameters\n",
    "rd = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = './data/SELECTED/'\n",
    "dbs = glob.glob(selected + '*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/SELECTED/realEstate.csv',\n",
       " './data/SELECTED/humandevel.csv',\n",
       " './data/SELECTED/cpu.csv',\n",
       " './data/SELECTED/disclosurez.csv',\n",
       " './data/SELECTED/sin1100.csv',\n",
       " './data/SELECTED/bikeSharingDay.csv',\n",
       " './data/SELECTED/bodyfat.csv',\n",
       " './data/SELECTED/bostonCorrected.csv',\n",
       " './data/SELECTED/polynomial.csv',\n",
       " './data/SELECTED/mpg.csv',\n",
       " './data/SELECTED/auto93.csv',\n",
       " './data/SELECTED/poly5100.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = ['./data/SELECTED/auto93.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Data set 1 >>>> auto93\n",
      "> Training models\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./beta_irt/results/auto93/irt_ability_vi_auto93_s17_f0_sd42_am1@0_as1@0.csv' does not exist: b'./beta_irt/results/auto93/irt_ability_vi_auto93_s17_f0_sd42_am1@0_as1@0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-48b3f7579ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./beta_irt/errors_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'irt_ability_vi_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname_\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_am1@0_as1@0.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'irt_parameters_vi_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname_\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_am1@0_as1@0.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/irt-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./beta_irt/results/auto93/irt_ability_vi_auto93_s17_f0_sd42_am1@0_as1@0.csv' does not exist: b'./beta_irt/results/auto93/irt_ability_vi_auto93_s17_f0_sd42_am1@0_as1@0.csv'"
     ]
    }
   ],
   "source": [
    "##############################READING ALL DATASETS##############################\n",
    "\n",
    "for d, db in enumerate(dbs):\n",
    "    print('\\n------------------------------------------------------------\\n')\n",
    "\n",
    "    # Creating folders   \n",
    "    name = db.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    print('Data set ' + str(d + 1) + ' >>>> ' + name)\n",
    "    \n",
    "    if not os.path.isdir('./beta_irt/results/'+ name):\n",
    "        os.system('mkdir ./beta_irt/results/'+ name)\n",
    "    \n",
    "    # Read file\n",
    "    df = pd.read_csv(db, na_values=['?'])\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    #Variable selection\n",
    "    if df.shape[1] > 2:\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "        \n",
    "        # Principal component analysis\n",
    "#         pca = PCA(n_components= 1)\n",
    "#         X_train = pca.fit_transform(X_train)\n",
    "#         X_test = pca.transform(X_test)\n",
    "    else: \n",
    "        X = df.iloc[:, 0].values.reshape(-1,1)\n",
    "        y = df.iloc[:, -1].values\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = rd)\n",
    "    \n",
    "    # Standard scale\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "    \n",
    "    sc_y = StandardScaler()\n",
    "    y_train = sc_y.fit_transform(y_train.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    y_test = sc_y.transform(y_test.reshape(-1,1)).reshape(1,-1)[0]\n",
    "    \n",
    "    print('> Training models')\n",
    "    # Generate abilities/parameters for BIRT and other info.\n",
    "    Irt = IRTModel(models= models)\n",
    "    Irt.fit(X_train = X_train, y_train = y_train)\n",
    "\n",
    "    # Noise\n",
    "    rd = 42\n",
    "    noise_std = np.linspace(0, 0.61, 21)\n",
    "    max_std = noise_std.max()\n",
    "    \n",
    "    # Folders\n",
    "    path = './beta_irt/results/'\n",
    "    folder = name + '/'\n",
    "\n",
    "    #-------------------------------------Generate-BIRT-------------------------------------#\n",
    "\n",
    "    rep = 40\n",
    "    \n",
    "    noises = np.zeros((len(X_test), len(noise_std)))\n",
    "    errors = np.zeros((len(noise_std), len(X_test), len(models)))\n",
    "    responses = np.zeros((len(noise_std), len(X_test), len(models) + n_synth_models))\n",
    "    abilities = np.zeros((len(models) + n_synth_models, len(noise_std)))\n",
    "    params = np.zeros((len(noise_std), len(X_test), 2))\n",
    "    \n",
    "    for i, noise in enumerate(noise_std[:1]):\n",
    "        \n",
    "        name_ = name + '_s' + str(len(y_test)) + '_f' + str(i) + '_sd' + str(rd)\n",
    "        \n",
    "        for itr in range(rep):\n",
    "            # Generate noise to feature in test set\n",
    "#             noise_train = np.random.normal(loc=0.0, scale= noise, size= len(y_train))\n",
    "            noise_test = np.random.normal(loc=0.0, scale= noise, size= len(y_test))\n",
    "\n",
    "#             y_train_ = y_train + noise_train\n",
    "            y_test_ = y_test + noise_test\n",
    "\n",
    "            noises[:, i] += np.absolute(noise_test)\n",
    "\n",
    "            # Generate IRT matrix\n",
    "            Irt.irtMatrix(X_test= X_test, y_test= y_test_, noise_std = i, normalize= False, base_models= True, name= name, rd= rd)\n",
    "            responses[i] += Irt.irt_matrix\n",
    "\n",
    "            \n",
    "\n",
    "            # Generate Items' parameters and Respondents' abilities\n",
    "            os.chdir('./beta_irt/')\n",
    "            os.system('python betairt_test.py irt_data_' + name_ + '.csv')\n",
    "            os.chdir('..')\n",
    "\n",
    "            errors[i] += pd.read_csv('./beta_irt/errors_' + name_ + '.csv').iloc[:, :].values\n",
    "            abilities[:, i] += pd.read_csv(path + folder + 'irt_ability_vi_'+ name_ +'_am1@0_as1@0.csv').iloc[:-1, 1:].values.reshape(1,-1)[0]\n",
    "            params[i] += pd.read_csv(path + folder + 'irt_parameters_vi_'+ name_ +'_am1@0_as1@0.csv').values\n",
    "\n",
    "        responses[i] /= rep\n",
    "        noises[:, i] /= rep\n",
    "        errors[i] /= rep\n",
    "        abilities[:, i] /= rep\n",
    "        params[i] /= rep\n",
    "\n",
    "        # Move files to folder    \n",
    "        output = './Results_IRT/'+ folder + 'noise_' + str(i) + '/'\n",
    "        if not os.path.isdir('./Results_IRT/'+ folder):\n",
    "            os.system('mkdir ./Results_IRT/'+ folder)\n",
    "        if not os.path.isdir(output):\n",
    "            os.system('mkdir ' + output)\n",
    "\n",
    "        # ABILITY\n",
    "        pd.DataFrame(data= np.hstack((pd.read_csv(path + folder + 'irt_ability_vi_'+ name_ +'_am1@0_as1@0.csv').iloc[:-1, 0].values.reshape(-1,1),\n",
    "                                  abilities[:, i].reshape(-1,1))),\n",
    "                 columns = ['Models','Ability']).to_csv(path_or_buf= output + 'irt_ability_vi_'+ name_ + '.csv', index=False)\n",
    "\n",
    "        # PARAMETERS\n",
    "        pd.DataFrame(data= params[i], columns=['Difficulty','Discrimination']).to_csv(path_or_buf= output + 'irt_parameters_vi_'+ name_ + '.csv', index=False)\n",
    "\n",
    "        # NOISE\n",
    "        pd.DataFrame(data= noises[:, i].reshape(-1,1), columns=['Noise']).to_csv(path_or_buf= output + 'noise_'+ name_ + '.csv', index=False)\n",
    "\n",
    "        # ERRORS\n",
    "        pd.DataFrame(data= errors[i], columns=pd.read_csv(path + folder + 'irt_ability_vi_'+ name_ +'_am1@0_as1@0.csv').iloc[:-4, 0].values).to_csv(path_or_buf= output + 'errors_'+ name_ + '.csv', index=False)\n",
    "\n",
    "        # RESPONSES\n",
    "        pd.DataFrame(data= responses[i], columns=pd.read_csv(path + folder + 'irt_ability_vi_'+ name_ +'_am1@0_as1@0.csv').iloc[:-1, 0].values).to_csv(output + 'irt_data_' + name_ + '.csv', index=False)\n",
    "\n",
    "        # X_TEST\n",
    "        pd.DataFrame(data = np.hstack((X_test, y_test_.reshape(-1,1)))).to_csv(path_or_buf= output + 'test_'+ name_ + '.csv', index=False)\n",
    "\n",
    "    #-------------------------------------Clean-Files-------------------------------------#\n",
    "\n",
    "    os.system('rm ./beta_irt/*.csv')\n",
    "    os.system('rm ' +path + folder + '*.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
